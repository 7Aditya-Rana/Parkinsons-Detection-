Parkinsonâ€™s Disease Detection via Eye-Tracking

This project presents an eye-trackingâ€“based system for the early detection of Parkinsonâ€™s Disease using video analysis and machine learning. High-frame-rate eye movement recordings are processed to extract clinically relevant gaze features, which are then analyzed using temporal deep learning models. The system is designed to run on low-cost edge hardware, enabling portable and privacy-preserving screening.

âœ… Key Features

Eye landmark detection using MediaPipe Face Mesh

Robust gaze and eye-movement feature extraction using OpenCV and NumPy

Noise-aware data preprocessing and behavioral labeling

Temporal modeling using an LSTM neural network

High-speed video processing using a 100 FPS camera

Designed for edge deployment (Raspberry Pi)

Offline processing to ensure data privacy

Binary prediction: Parkinsonâ€™s / Non-Parkinsonâ€™s

ğŸ§  System & ML Pipeline Overview

Video Acquisition
Eye movement videos are recorded using a high-frame-rate camera to capture subtle eye dynamics.

Landmark Detection
Facial and eye landmarks are detected using MediaPipe to localize eye regions accurately.

Feature Extraction
Frame-wise eye features are extracted, including:

Eye Aspect Ratio (EAR)

Blink detection

Saccade velocity

Fixation (visual intake) detection

Pupil diameter and pupil center coordinates

Binocular Point of Regard (PoR)

Data Preprocessing

Noise reduction using median filtering

Handling of missing or blank frames

Removal of spurious micro-movements

Semantic labeling of eye behavior (blink, saccade, fixation)

Temporal Modeling
Cleaned frame-level features are organized into fixed-length sequences suitable for time-series learning.

Model Inference
An LSTM model analyzes temporal eye-movement patterns and outputs a probability score indicating Parkinsonâ€™s likelihood.

ğŸ—ƒ Project Structure
ğŸ“ eye_parkinsons_project/
â”‚
â”œâ”€â”€ main.py                    # Entry point for video processing pipeline
â”œâ”€â”€ pipeline.py                # Feature extraction and sequence construction
â”œâ”€â”€ model.py                   # LSTM model definition and inference
â”œâ”€â”€ preprocessing.py           # Noise removal and data cleaning logic
â”œâ”€â”€ utils.py                   # EAR, blink, saccade, fixation, PoR functions
â”œâ”€â”€ models/
â”‚   â””â”€â”€ lstm_model.pt          # Trained LSTM model
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_video.mp4       # Example input video
â”œâ”€â”€ eye_metrics_output.csv     # Frame-wise extracted features
â””â”€â”€ README.md

âš™ï¸ Requirements
pip install -r requirements.txt


Core Dependencies

Python 3.8+

OpenCV

MediaPipe

NumPy, Pandas

PyTorch (for LSTM)

Optional

Streamlit (for UI)

Docker (for full pipeline integration)

ğŸš€ How to Run
Process a Recorded Video
python main.py --video data/sample_video.mp4

Live Capture (Edge Device)
python main.py --live

Output

eye_metrics_output.csv â€“ cleaned and structured gaze features

Console output â€“ Parkinsonâ€™s prediction with confidence

ğŸ“Š Sample Features Extracted
Feature	Description
Eye Aspect Ratio	Measures eye openness for blink detection
Saccade Velocity	Speed of gaze movement between frames
Fixation Flag	Indicates stable visual attention
Blink Indicator	Frame-level blink detection
Pupil Diameter	Approximate pupil size (left & right eyes)
Point of Regard	Estimated binocular gaze location
ğŸ³ Docker Integration

The complete pipeline is containerized using Docker, ensuring:

consistent runtime environment,

easy deployment across systems,

reproducibility of results,

simplified dependency management.

This makes the system suitable for deployment on edge devices and future clinical setups.

ğŸ”® Future Improvements

Validation on larger and more diverse clinical datasets

Integration of multimodal biomarkers (speech, handwriting)

Model optimization for faster edge inference

Conversion to ONNX / TensorFlow Lite for embedded deployment

Real-time feedback interface for clinicians


